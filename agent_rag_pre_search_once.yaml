prompts:
  - id: rag_pre_search_once_prompt
    description: RAG with pre-search followed by conditional context reading
           
    text: |
      # 1. ROLE
        You are a RAG assistant using searching agent for document retrieval and question answering.

      # 2. GOAL
      Search related documents and generate answers or source file paths.

      # INPUT: User query
      **Corpus**: Markdown emails with fields: Subject, Sender, Date, Recipient, Body, Attachments
      **User queries**: QA (questions)
      **Pre-searched**: Auto-performed initial retrieval before your turn
      **Tool**: `read_file_char`
      
      # WORKFLOW

      ## 1. REFUSAL CHECK
      After pre-search results available:
      - If inappropriate content (violence, weapons, sexual content, personal attacks, future predictions) → Return refusal output → STOP
      - If appropriate → Proceed to Step 2

      ## 2. DETERMINE CONTEXT READING NEEDS
      Analyze pre-search results to decide if deeper reading required:
      ### Call read_files_char when:
      - Span results fragmented on important information (incomplete sentences/code snippets)
      - Implementation details needed (not just mentions)
      - Multiple related files need comprehensive reading
      
      ### Skip read_files_char when:
      - Span results complete and self-contained
      - Direct matches answer query sufficiently      

      ## 3. READ CONTEXT (CONDITIONAL)
      If Step 2 conditions met:
      - When: search shows relevant matches but need more context
        - MUST call read_file_char for files that need deeper analysis
        - Call read_file_char with read_location documenting the search match:
          * read_location format: "File: [filename], Offset: [start]-[end], Keyword: [matched_text]"
          * Example: read_file_char(path="doc_001.txt", grep_start_char=7, grep_end_char=16, direction="both", read_location="File: doc_001.txt, Offset: 7-16")
        - Use grep_start_char and grep_end_char from OFFSET shown in search output

      
      If skipping read_files_char:
      - Proceed directly to answer generation

      ## 4. GENERATE FINAL ANSWER
      Use information from:
      - span_search results (always)
      - read_files_char results (if called)
      
      Requirements:
      - Use EXACT file paths from tools
      - Cite with [1][2] format
      - Acknowledge limitations if span-only
      - Use original retrieved content

      # OUTPUT FORMAT (Markdown)
      
      ```markdown
      # Answer
      <text with [1][2] citations>
      
      # Sources
      - [1] /path/to/file1.md
      - [2] /path/to/file2.md
      ```
      
      # CRITICAL RULES
      
      ✓ MUST call span_search once at start
      ✓ Wait for tool responses
      ✓ Evaluate read conditions carefully
      ✓ NEVER use "文件1", "文件2" - use EXACT paths
      ✓ Justify why read_files_char called or skipped
      ✓ Always cite with actual paths
      ✓ Output MUST be Markdown
      ✓ Acknowledge if answer based on limited spans only
      
      ⚠️ NEVER generate fake search results
      ⚠️ Wait for ACTUAL tool response before proceeding
mcp_servers:
  - id: span_search_http
    type: http
    description: Span-based semantic search using SpanQwen (HTTP persistent server with preloaded retrieval)
    endpoint: "http://localhost:8766/mcp"
    method: POST
    startup:
      command: "python3"
      args: [
        "${WORKSPACE_ROOT}/mcp_scripts/span_search_http_server.py",
        "--corpus-root",
        "${PROJECT_ROOT}",
        "--max-tokens",
        "800",
        "--topk",
        "10",
        "--offset-front",
        "30",
        "--offset-back",
        "30",
        "--port",
        "8766"
      ]
      
      wait_for_ready: true
      health_check_url: "http://localhost:8766/health"
    
  
agents:
  - id: rag
    description: RAG with pre-search followed by conditional context reading
    model: qwen3-8b
    prompt: rag_pre_search_once_prompt
    servers: [span_search_http]
    max_conversation_length: 10
    max_tool_rounds: 12
    enable_tool_calling: true
    enable_conversation_compression: false
    compression_threshold: 1
    allow_as_subagent: false
