{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c25d824",
   "metadata": {},
   "source": [
    "# JSONæ•°æ®åˆ†æ - ç­›é€‰åŒ…å«'no response generated'çš„æ–‡ä»¶\n",
    "\n",
    "æœ¬notebookç”¨äºåˆ†æå®éªŒæ•°æ®ç›®å½•ä¸­çš„JSONæ–‡ä»¶ï¼Œç­›é€‰å‡ºåŒ…å«'no response generated'å­—æ®µçš„æ–‡ä»¶å¹¶ç»Ÿè®¡æ•°é‡ã€‚\n",
    "\n",
    "**æ•°æ®è·¯å¾„**: `/home/dyvm6xra/dyvm6xrauser44/wujiamin/AgenticRAG/rag_evals/results/aip_rag_perf/old/experiment_20251211_113947/processed_json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20e427",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥æ‰€éœ€åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985f521",
   "metadata": {},
   "source": [
    "## 2. å®šä¹‰æ•°æ®è·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce953c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®å®éªŒæ•°æ®ç›®å½•è·¯å¾„\n",
    "base_dir = \"/home/dyvm6xra/dyvm6xrauser44/wujiamin/AgenticRAG/rag_evals/results/aip_rag_perf/old/experiment_20251211_113947\"\n",
    "processed_json_dir = os.path.join(base_dir, \"processed_json\")\n",
    "\n",
    "# æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨\n",
    "if os.path.exists(processed_json_dir):\n",
    "    print(f\"âœ“ æ•°æ®ç›®å½•å­˜åœ¨: {processed_json_dir}\")\n",
    "    # åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
    "    json_files = [f for f in os.listdir(processed_json_dir) if f.endswith('.json')]\n",
    "    print(f\"âœ“ æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶\")\n",
    "else:\n",
    "    print(f\"âœ— æ•°æ®ç›®å½•ä¸å­˜åœ¨: {processed_json_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2b655",
   "metadata": {},
   "source": [
    "## 3. å®šä¹‰æœç´¢å‡½æ•°\n",
    "\n",
    "å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥é€’å½’æœç´¢JSONä¸­æ‰€æœ‰åŒ…å«ç‰¹å®šå­—ç¬¦ä¸²çš„ä½ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_no_response(data, search_string=\"no response generated\"):\n",
    "    \"\"\"\n",
    "    é€’å½’æœç´¢JSONæ•°æ®ä¸­æ˜¯å¦åŒ…å«æŒ‡å®šå­—ç¬¦ä¸²ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰\n",
    "    \n",
    "    å‚æ•°:\n",
    "        data: JSONæ•°æ®ï¼ˆdict, list, strç­‰ï¼‰\n",
    "        search_string: è¦æœç´¢çš„å­—ç¬¦ä¸²\n",
    "    \n",
    "    è¿”å›:\n",
    "        bool: å¦‚æœæ‰¾åˆ°åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False\n",
    "    \"\"\"\n",
    "    search_lower = search_string.lower()\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        for value in data.values():\n",
    "            if contains_no_response(value, search_string):\n",
    "                return True\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            if contains_no_response(item, search_string):\n",
    "                return True\n",
    "    elif isinstance(data, str):\n",
    "        if search_lower in data.lower():\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e59af",
   "metadata": {},
   "source": [
    "## 4. åˆ†ææ‰€æœ‰JSONæ–‡ä»¶\n",
    "\n",
    "éå†æ‰€æœ‰JSONæ–‡ä»¶ï¼Œæ‰¾å‡ºåŒ…å«'no response generated'çš„æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­˜å‚¨åŒ…å«'no response generated'çš„æ–‡ä»¶åˆ—è¡¨\n",
    "files_with_no_response = []\n",
    "\n",
    "# éå†æ‰€æœ‰JSONæ–‡ä»¶\n",
    "for json_file in json_files:\n",
    "    file_path = os.path.join(processed_json_dir, json_file)\n",
    "    \n",
    "    try:\n",
    "        # è¯»å–JSONæ–‡ä»¶\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦åŒ…å«'no response generated'\n",
    "        if contains_no_response(data):\n",
    "            files_with_no_response.append(json_file)\n",
    "            print(f\"âœ“ {json_file} - åŒ…å« 'no response generated'\")\n",
    "        else:\n",
    "            print(f\"  {json_file} - ä¸åŒ…å«\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— è¯»å–æ–‡ä»¶å‡ºé”™ {json_file}: {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b4f43d",
   "metadata": {},
   "source": [
    "## 5. ç»Ÿè®¡ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4637428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»Ÿè®¡ç»“æœ\n",
    "total_files = len(json_files)\n",
    "files_with_issue = len(files_with_no_response)\n",
    "\n",
    "print(f\"ğŸ“Š ç»Ÿè®¡ç»“æœ:\")\n",
    "print(f\"   æ€»æ–‡ä»¶æ•°: {total_files}\")\n",
    "print(f\"   åŒ…å«'no response generated'çš„æ–‡ä»¶æ•°: {files_with_issue}\")\n",
    "print(f\"   ç™¾åˆ†æ¯”: {(files_with_issue/total_files*100):.2f}%\")\n",
    "print(\"\\nåŒ…å«'no response generated'çš„æ–‡ä»¶åˆ—è¡¨:\")\n",
    "for i, filename in enumerate(files_with_no_response, 1):\n",
    "    print(f\"   {i}. {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909d7ff",
   "metadata": {},
   "source": [
    "## 6. è¯¦ç»†åˆ†æï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "æŸ¥çœ‹æ¯ä¸ªæ–‡ä»¶ä¸­å…·ä½“å“ªäº›å­—æ®µåŒ…å«'no response generated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_no_response_paths(data, search_string=\"no response generated\", path=\"\"):\n",
    "    \"\"\"\n",
    "    é€’å½’æœç´¢JSONæ•°æ®ï¼Œè¿”å›åŒ…å«æŒ‡å®šå­—ç¬¦ä¸²çš„æ‰€æœ‰è·¯å¾„\n",
    "    \n",
    "    å‚æ•°:\n",
    "        data: JSONæ•°æ®\n",
    "        search_string: è¦æœç´¢çš„å­—ç¬¦ä¸²\n",
    "        path: å½“å‰è·¯å¾„\n",
    "    \n",
    "    è¿”å›:\n",
    "        list: åŒ…å«åŒ¹é…å­—ç¬¦ä¸²çš„è·¯å¾„åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    search_lower = search_string.lower()\n",
    "    paths = []\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            new_path = f\"{path}.{key}\" if path else key\n",
    "            paths.extend(find_no_response_paths(value, search_string, new_path))\n",
    "    elif isinstance(data, list):\n",
    "        for i, item in enumerate(data):\n",
    "            new_path = f\"{path}[{i}]\"\n",
    "            paths.extend(find_no_response_paths(item, search_string, new_path))\n",
    "    elif isinstance(data, str):\n",
    "        if search_lower in data.lower():\n",
    "            paths.append(path)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "# å¯¹æ¯ä¸ªåŒ…å«é—®é¢˜çš„æ–‡ä»¶è¿›è¡Œè¯¦ç»†åˆ†æ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è¯¦ç»†åˆ†æ - æŸ¥çœ‹å…·ä½“ä½ç½®:\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for json_file in files_with_no_response:\n",
    "    file_path = os.path.join(processed_json_dir, json_file)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    paths = find_no_response_paths(data)\n",
    "    print(f\"\\nğŸ“„ {json_file}\")\n",
    "    print(f\"   æ‰¾åˆ° {len(paths)} ä¸ªä½ç½®åŒ…å« 'no response generated':\")\n",
    "    for i, path in enumerate(paths[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª\n",
    "        print(f\"   {i}. {path}\")\n",
    "    if len(paths) > 5:\n",
    "        print(f\"   ... è¿˜æœ‰ {len(paths)-5} ä¸ªä½ç½®\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
