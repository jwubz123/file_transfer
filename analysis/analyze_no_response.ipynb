{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c25d824",
   "metadata": {},
   "source": [
    "# JSONæ•°æ®åˆ†æ - ç­›é€‰åŒ…å«'no response generated'çš„æ–‡ä»¶\n",
    "\n",
    "æœ¬notebookç”¨äºåˆ†æå®éªŒæ•°æ®ç›®å½•ä¸­çš„JSONæ–‡ä»¶ï¼Œç­›é€‰å‡ºåŒ…å«'no response generated'å­—æ®µçš„æ–‡ä»¶å¹¶ç»Ÿè®¡æ•°é‡ã€‚\n",
    "\n",
    "**æ•°æ®è·¯å¾„**: `/home/dyvm6xra/dyvm6xrauser44/wujiamin/AgenticRAG/rag_evals/results/aip_rag_perf/old/experiment_20251211_113947/processed_json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20e427",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥æ‰€éœ€åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985f521",
   "metadata": {},
   "source": [
    "## 2. å®šä¹‰æ•°æ®è·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce953c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®å®éªŒæ•°æ®ç›®å½•è·¯å¾„\n",
    "base_dir = \"/home/dyvm6xra/dyvm6xrauser44/wujiamin/AgenticRAG/rag_evals/results/aip_rag_perf/old/experiment_20251211_113947\"\n",
    "processed_json_dir = os.path.join(base_dir, \"processed_json\")\n",
    "\n",
    "# æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨\n",
    "if os.path.exists(processed_json_dir):\n",
    "    print(f\"âœ“ æ•°æ®ç›®å½•å­˜åœ¨: {processed_json_dir}\")\n",
    "    # åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
    "    json_files = [f for f in os.listdir(processed_json_dir) if f.endswith('.json')]\n",
    "    print(f\"âœ“ æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶\")\n",
    "else:\n",
    "    print(f\"âœ— æ•°æ®ç›®å½•ä¸å­˜åœ¨: {processed_json_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2b655",
   "metadata": {},
   "source": [
    "## 3. å®šä¹‰æœç´¢å‡½æ•°\n",
    "\n",
    "å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥é€’å½’æœç´¢JSONä¸­æ‰€æœ‰åŒ…å«ç‰¹å®šå­—ç¬¦ä¸²çš„ä½ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_no_response(data, search_string=\"no response generated\"):\n",
    "    \"\"\"\n",
    "    é€’å½’æœç´¢JSONæ•°æ®ä¸­æ˜¯å¦åŒ…å«æŒ‡å®šå­—ç¬¦ä¸²ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰\n",
    "    \n",
    "    å‚æ•°:\n",
    "        data: JSONæ•°æ®ï¼ˆdict, list, strç­‰ï¼‰\n",
    "        search_string: è¦æœç´¢çš„å­—ç¬¦ä¸²\n",
    "    \n",
    "    è¿”å›:\n",
    "        bool: å¦‚æœæ‰¾åˆ°åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False\n",
    "    \"\"\"\n",
    "    search_lower = search_string.lower()\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        for value in data.values():\n",
    "            if contains_no_response(value, search_string):\n",
    "                return True\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            if contains_no_response(item, search_string):\n",
    "                return True\n",
    "    elif isinstance(data, str):\n",
    "        if search_lower in data.lower():\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def count_string_occurrences(data, search_string=\"no response generated\"):\n",
    "    \"\"\"\n",
    "    é€’å½’ç»Ÿè®¡JSONæ•°æ®ä¸­æŒ‡å®šå­—ç¬¦ä¸²å‡ºç°çš„æ¬¡æ•°ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰\n",
    "    \n",
    "    å‚æ•°:\n",
    "        data: JSONæ•°æ®ï¼ˆdict, list, strç­‰ï¼‰\n",
    "        search_string: è¦æœç´¢çš„å­—ç¬¦ä¸²\n",
    "    \n",
    "    è¿”å›:\n",
    "        int: å­—ç¬¦ä¸²å‡ºç°çš„æ¬¡æ•°\n",
    "    \"\"\"\n",
    "    search_lower = search_string.lower()\n",
    "    count = 0\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        for value in data.values():\n",
    "            count += count_string_occurrences(value, search_string)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            count += count_string_occurrences(item, search_string)\n",
    "    elif isinstance(data, str):\n",
    "        if search_lower in data.lower():\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e59af",
   "metadata": {},
   "source": [
    "## 4. åˆ†ææ‰€æœ‰JSONæ–‡ä»¶\n",
    "\n",
    "éå†æ‰€æœ‰JSONæ–‡ä»¶ï¼Œæ‰¾å‡ºåŒ…å«'no response generated'çš„æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­˜å‚¨åŒ…å«'no response generated'çš„æ–‡ä»¶åˆ—è¡¨\n",
    "files_with_no_response = []\n",
    "\n",
    "# éå†æ‰€æœ‰JSONæ–‡ä»¶\n",
    "for json_file in json_files:\n",
    "    file_path = os.path.join(processed_json_dir, json_file)\n",
    "    \n",
    "    try:\n",
    "        # è¯»å–JSONæ–‡ä»¶\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦åŒ…å«'no response generated'\n",
    "        if contains_no_response(data):\n",
    "            files_with_no_response.append(json_file)\n",
    "            print(f\"âœ“ {json_file} - åŒ…å« 'no response generated'\")\n",
    "        else:\n",
    "            print(f\"  {json_file} - ä¸åŒ…å«\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— è¯»å–æ–‡ä»¶å‡ºé”™ {json_file}: {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b4f43d",
   "metadata": {},
   "source": [
    "## 6. åŸºæœ¬ç»Ÿè®¡ç»“æœï¼ˆè‡³å°‘å‡ºç°1æ¬¡ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11ce5e",
   "metadata": {},
   "source": [
    "## 5. æŒ‰å‡ºç°æ¬¡æ•°ç­›é€‰æ–‡ä»¶\n",
    "\n",
    "ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶ä¸­å­—ç¬¦ä¸²çš„å‡ºç°æ¬¡æ•°ï¼Œå¹¶ç­›é€‰å‡ºç°æ¬¡æ•°è¶…è¿‡kæ¬¡çš„æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®å‚æ•°\n",
    "search_string = \"no response generated\"  # è¦æœç´¢çš„å­—ç¬¦ä¸²\n",
    "min_occurrences = 1  # æœ€å°å‡ºç°æ¬¡æ•°é˜ˆå€¼ï¼ˆkå€¼ï¼‰\n",
    "\n",
    "# ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶ä¸­å­—ç¬¦ä¸²çš„å‡ºç°æ¬¡æ•°\n",
    "file_occurrence_counts = {}\n",
    "\n",
    "print(f\"æ­£åœ¨ç»Ÿè®¡ '{search_string}' çš„å‡ºç°æ¬¡æ•°...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for json_file in json_files:\n",
    "    file_path = os.path.join(processed_json_dir, json_file)\n",
    "    \n",
    "    try:\n",
    "        # è¯»å–JSONæ–‡ä»¶\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # ç»Ÿè®¡å‡ºç°æ¬¡æ•°\n",
    "        count = count_string_occurrences(data, search_string)\n",
    "        file_occurrence_counts[json_file] = count\n",
    "        \n",
    "        if count > 0:\n",
    "            print(f\"ğŸ“„ {json_file}: {count} æ¬¡\")\n",
    "        else:\n",
    "            print(f\"   {json_file}: 0 æ¬¡\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— è¯»å–æ–‡ä»¶å‡ºé”™ {json_file}: {str(e)}\")\n",
    "        file_occurrence_counts[json_file] = 0\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8b0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç­›é€‰å‡ºç°æ¬¡æ•°è¶…è¿‡kæ¬¡çš„æ–‡ä»¶\n",
    "files_above_threshold = {\n",
    "    filename: count \n",
    "    for filename, count in file_occurrence_counts.items() \n",
    "    if count > min_occurrences\n",
    "}\n",
    "\n",
    "# æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº\n",
    "sorted_files = sorted(files_above_threshold.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nğŸ“Š ç­›é€‰ç»“æœ (å‡ºç°æ¬¡æ•° > {min_occurrences}):\")\n",
    "print(f\"   ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶æ•°: {len(sorted_files)}\")\n",
    "print(f\"\\næ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰å‡ºç°æ¬¡æ•°é™åºï¼‰:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, (filename, count) in enumerate(sorted_files, 1):\n",
    "    print(f\"{i:2d}. {filename}: {count} æ¬¡\")\n",
    "\n",
    "if len(sorted_files) == 0:\n",
    "    print(f\"   æ²¡æœ‰æ–‡ä»¶çš„å‡ºç°æ¬¡æ•°è¶…è¿‡ {min_occurrences} æ¬¡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e030278",
   "metadata": {},
   "source": [
    "## 5.1 æ•°æ®å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "ä½¿ç”¨pandas DataFrameå±•ç¤ºç»Ÿè®¡ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºDataFrameç”¨äºæ•°æ®å±•ç¤º\n",
    "df_stats = pd.DataFrame([\n",
    "    {\"æ–‡ä»¶å\": filename, \"å‡ºç°æ¬¡æ•°\": count} \n",
    "    for filename, count in file_occurrence_counts.items()\n",
    "])\n",
    "\n",
    "# æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº\n",
    "df_stats = df_stats.sort_values(\"å‡ºç°æ¬¡æ•°\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# æ·»åŠ åºå·åˆ—\n",
    "df_stats.index = df_stats.index + 1\n",
    "\n",
    "print(\"\\nå®Œæ•´ç»Ÿè®¡è¡¨æ ¼:\")\n",
    "print(\"=\"*80)\n",
    "display(df_stats)\n",
    "\n",
    "# ç»Ÿè®¡ä¿¡æ¯\n",
    "print(f\"\\næ±‡æ€»ç»Ÿè®¡:\")\n",
    "print(f\"  æ€»æ–‡ä»¶æ•°: {len(df_stats)}\")\n",
    "print(f\"  åŒ…å«ç›®æ ‡å­—ç¬¦ä¸²çš„æ–‡ä»¶æ•°: {len(df_stats[df_stats['å‡ºç°æ¬¡æ•°'] > 0])}\")\n",
    "print(f\"  ä¸åŒ…å«ç›®æ ‡å­—ç¬¦ä¸²çš„æ–‡ä»¶æ•°: {len(df_stats[df_stats['å‡ºç°æ¬¡æ•°'] == 0])}\")\n",
    "print(f\"  æ€»å‡ºç°æ¬¡æ•°: {df_stats['å‡ºç°æ¬¡æ•°'].sum()}\")\n",
    "print(f\"  å¹³å‡å‡ºç°æ¬¡æ•°: {df_stats['å‡ºç°æ¬¡æ•°'].mean():.2f}\")\n",
    "print(f\"  æœ€å¤§å‡ºç°æ¬¡æ•°: {df_stats['å‡ºç°æ¬¡æ•°'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4637428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»Ÿè®¡ç»“æœ\n",
    "total_files = len(json_files)\n",
    "files_with_issue = len(files_with_no_response)\n",
    "\n",
    "print(f\"ğŸ“Š ç»Ÿè®¡ç»“æœ:\")\n",
    "print(f\"   æ€»æ–‡ä»¶æ•°: {total_files}\")\n",
    "print(f\"   åŒ…å«'no response generated'çš„æ–‡ä»¶æ•°: {files_with_issue}\")\n",
    "print(f\"   ç™¾åˆ†æ¯”: {(files_with_issue/total_files*100):.2f}%\")\n",
    "print(\"\\nåŒ…å«'no response generated'çš„æ–‡ä»¶åˆ—è¡¨:\")\n",
    "for i, filename in enumerate(files_with_no_response, 1):\n",
    "    print(f\"   {i}. {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909d7ff",
   "metadata": {},
   "source": [
    "## 7. è¯¦ç»†åˆ†æï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "æŸ¥çœ‹æ¯ä¸ªæ–‡ä»¶ä¸­å…·ä½“å“ªäº›å­—æ®µåŒ…å«'no response generated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_no_response_paths(data, search_string=\"no response generated\", path=\"\"):\n",
    "    \"\"\"\n",
    "    é€’å½’æœç´¢JSONæ•°æ®ï¼Œè¿”å›åŒ…å«æŒ‡å®šå­—ç¬¦ä¸²çš„æ‰€æœ‰è·¯å¾„\n",
    "    \n",
    "    å‚æ•°:\n",
    "        data: JSONæ•°æ®\n",
    "        search_string: è¦æœç´¢çš„å­—ç¬¦ä¸²\n",
    "        path: å½“å‰è·¯å¾„\n",
    "    \n",
    "    è¿”å›:\n",
    "        list: åŒ…å«åŒ¹é…å­—ç¬¦ä¸²çš„è·¯å¾„åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    search_lower = search_string.lower()\n",
    "    paths = []\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            new_path = f\"{path}.{key}\" if path else key\n",
    "            paths.extend(find_no_response_paths(value, search_string, new_path))\n",
    "    elif isinstance(data, list):\n",
    "        for i, item in enumerate(data):\n",
    "            new_path = f\"{path}[{i}]\"\n",
    "            paths.extend(find_no_response_paths(item, search_string, new_path))\n",
    "    elif isinstance(data, str):\n",
    "        if search_lower in data.lower():\n",
    "            paths.append(path)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "# å¯¹æ¯ä¸ªåŒ…å«é—®é¢˜çš„æ–‡ä»¶è¿›è¡Œè¯¦ç»†åˆ†æ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è¯¦ç»†åˆ†æ - æŸ¥çœ‹å…·ä½“ä½ç½®:\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for json_file in files_with_no_response:\n",
    "    file_path = os.path.join(processed_json_dir, json_file)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    paths = find_no_response_paths(data)\n",
    "    print(f\"\\nğŸ“„ {json_file}\")\n",
    "    print(f\"   æ‰¾åˆ° {len(paths)} ä¸ªä½ç½®åŒ…å« 'no response generated':\")\n",
    "    for i, path in enumerate(paths[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª\n",
    "        print(f\"   {i}. {path}\")\n",
    "    if len(paths) > 5:\n",
    "        print(f\"   ... è¿˜æœ‰ {len(paths)-5} ä¸ªä½ç½®\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
